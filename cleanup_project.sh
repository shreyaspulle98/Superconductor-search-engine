#!/bin/bash

# Project Cleanup Script
# ======================
# Moves old/unnecessary files to archive while keeping essential code

echo "======================================================================"
echo "ğŸ§¹ PROJECT CLEANUP"
echo "======================================================================"

# Create archive structure
mkdir -p archive/old_scripts
mkdir -p archive/old_docs
mkdir -p archive/logs

echo ""
echo "ğŸ“ Moving old/redundant files to archive..."

# Move old training/testing scripts (replaced by v2 versions)
mv 02.train_model.py archive/old_scripts/ 2>/dev/null
mv 03_build_search_index.py archive/old_scripts/ 2>/dev/null
mv 04_test_search.py archive/old_scripts/ 2>/dev/null

# Move old documentation (superseded)
mv DATA_SOURCE_RECOMMENDATIONS.md archive/old_docs/ 2>/dev/null
mv HOW_TO_USE_QUERY_GENERATOR.md archive/old_docs/ 2>/dev/null
mv MODEL_ANALYSIS_AND_IMPROVEMENT_PLAN.md archive/old_docs/ 2>/dev/null
mv SAMPLE_QUERIES_MANUAL.md archive/old_docs/ 2>/dev/null
mv UPLOAD_INSTRUCTIONS.md archive/old_docs/ 2>/dev/null

# Move temporary/helper scripts to archive
mv fetch_all_transcripts.py archive/old_scripts/ 2>/dev/null
mv fetch_youtube_titles.py archive/old_scripts/ 2>/dev/null
mv fetch_youtube_transcripts.py archive/old_scripts/ 2>/dev/null
mv format_youtube_documents.py archive/old_scripts/ 2>/dev/null
mv scripts/merge_data.py archive/old_scripts/ 2>/dev/null 2>/dev/null

# Move logs
mv youtube_scraper.log archive/logs/ 2>/dev/null
mv youtube_video_ids.txt archive/logs/ 2>/dev/null

# Remove old web UI (will create new one for HuggingFace)
mv web_ui.py archive/old_scripts/ 2>/dev/null

echo "   âœ… Moved old files to archive"

echo ""
echo "ğŸ“Š Final Project Structure:"
echo ""
echo "Essential Scripts:"
echo "â”œâ”€â”€ Data Collection (0.x_*.py)"
echo "â”‚   â”œâ”€â”€ 0.1_superconductor_scraper.py      (Wikipedia scraper)"
echo "â”‚   â”œâ”€â”€ 0.1b_simple_wikipedia_scraper.py   (Simple Wikipedia)"
echo "â”‚   â”œâ”€â”€ 0.2_mit_OCW_scraper.py             (MIT OCW)"
echo "â”‚   â”œâ”€â”€ 0.3_youtube_maximiser_scraper.py   (YouTube scraper)"
echo "â”‚   â”œâ”€â”€ 0.4_merge_datasets.py              (Dataset merger)"
echo "â”‚   â”œâ”€â”€ 0.5_arxiv_full_papers.py           (arXiv papers)"
echo "â”‚   â”œâ”€â”€ 0.6_scholarpedia_scraper.py        (Scholarpedia)"
echo "â”‚   â””â”€â”€ 0.7_hyperphysics_scraper.py        (HyperPhysics)"
echo "â”‚"
echo "â”œâ”€â”€ Data Quality Pipeline"
echo "â”‚   â”œâ”€â”€ generate_queries_llm.py            (Query generation)"
echo "â”‚   â”œâ”€â”€ create_hard_negatives.py           (Hard negatives)"
echo "â”‚   â”œâ”€â”€ fix_weak_positive_pairings.py      (Weak pairing removal)"
echo "â”‚   â”œâ”€â”€ deep_quality_check.py              (Deep quality analysis)"
echo "â”‚   â”œâ”€â”€ final_cleanup.py                   (Final cleanup)"
echo "â”‚   â””â”€â”€ prepare_for_training.py            (Training preparation)"
echo "â”‚"
echo "â”œâ”€â”€ Model Training & Testing"
echo "â”‚   â”œâ”€â”€ train_model_v2.py                  (Training script)"
echo "â”‚   â”œâ”€â”€ build_search_index.py              (Index builder)"
echo "â”‚   â”œâ”€â”€ test_search_model.py               (Comprehensive tests)"
echo "â”‚   â””â”€â”€ interactive_search.py              (Interactive search CLI)"
echo "â”‚"
echo "â””â”€â”€ Deployment"
echo "    â””â”€â”€ app.py                             (Gradio web interface)"
echo ""
echo "Data:"
echo "â”œâ”€â”€ training/                              (Production training data)"
echo "â”‚   â”œâ”€â”€ training_dataset.json             (4,546 examples)"
echo "â”‚   â”œâ”€â”€ documents.json                     (1,762 documents)"
echo "â”‚   â””â”€â”€ training_metadata.json             (Metadata)"
echo "â”‚"
echo "â”œâ”€â”€ search_index/                          (Production search index)"
echo "â”‚   â”œâ”€â”€ faiss_index.bin                    (FAISS index)"
echo "â”‚   â”œâ”€â”€ document_metadata.json             (Metadata)"
echo "â”‚   â””â”€â”€ index_info.json                    (Index info)"
echo "â”‚"
echo "â”œâ”€â”€ models/                                (Trained models)"
echo "â”‚   â””â”€â”€ superconductor-search-v2/          (Latest model)"
echo "â”‚"
echo "â”œâ”€â”€ data/                                  (Processed/raw data)"
echo "â”‚   â”œâ”€â”€ processed/                         (Final datasets)"
echo "â”‚   â””â”€â”€ raw/                               (Source data)"
echo "â”‚"
echo "â””â”€â”€ archive/                               (Old/intermediate files)"
echo ""

echo "======================================================================"
echo "âœ… CLEANUP COMPLETE!"
echo "======================================================================"
echo ""
echo "Essential files kept:"
echo "   ğŸ”§ All data collection scripts (0.x)"
echo "   ğŸ“Š Data quality pipeline scripts"
echo "   ğŸ¤– Training and testing scripts (v2)"
echo "   ğŸš€ Deployment files (app.py)"
echo "   ğŸ“š Production data (training/, search_index/, models/)"
echo "   ğŸ“ Documentation (README.md, summaries)"
echo ""
echo "Archived:"
echo "   ğŸ“¦ Old scripts (archive/old_scripts/)"
echo "   ğŸ“„ Old documentation (archive/old_docs/)"
echo "   ğŸ“‹ Logs (archive/logs/)"
echo ""
echo "======================================================================"
